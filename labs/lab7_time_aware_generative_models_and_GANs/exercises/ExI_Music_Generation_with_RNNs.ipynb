{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zT-pm6Rp5oTr"
      },
      "source": [
        "# Music Generation with RNNs\n",
        "\n",
        "We will explore the application of Recurrent Neural Networks (RNN) for music generation. We will train a model to learn patterns contained in raw sheet music in ABC notation and then use the model to generate new music.\n",
        "\n",
        "> Blocco con rientro\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G9vzyj5v52m_"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dWuZnoBj545Y"
      },
      "source": [
        "# Import Tensorflow 2.0\n",
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf \n",
        "\n",
        "# Download and import the MIT 6.S191 package\n",
        "!pip install mitdeeplearning\n",
        "import mitdeeplearning as mdl\n",
        "\n",
        "# Import all remaining packages\n",
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "import functools\n",
        "from IPython import display as ipythondisplay\n",
        "from tqdm import tqdm\n",
        "!apt-get install abcmidi timidity > /dev/null 2>&1\n",
        "\n",
        "# Check that we are using a GPU, if not switch runtimes\n",
        "#   using Runtime > Change Runtime Type > GPU\n",
        "assert len(tf.config.list_physical_devices('GPU')) > 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Ntp47Nz6I81"
      },
      "source": [
        "# Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jAwjh95R6MuA"
      },
      "source": [
        "# Download the dataset\n",
        "songs = mdl.lab1.load_training_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GR3bOwBM6UpN"
      },
      "source": [
        "# Print one of the songs to inspect it in more detail\n",
        "example_song = songs[0]\n",
        "print(\"\\nExample song:\")\n",
        "print(example_song)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pb5Upco56o8y"
      },
      "source": [
        "# Convert the ABC notation to audio file and listen to it\n",
        "mdl.lab1.play_song(example_song)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tz9HNkGN_sNT"
      },
      "source": [
        "N.B. the music notation used in this dataset does not just contain information relative to the notes being played, there is also meta-data related to\n",
        "* song title\n",
        "* song key\n",
        "* song tempo\n",
        "\n",
        "This will pose some constraint in the numerical representation of the text data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qffsxECY_81W"
      },
      "source": [
        "# Join our list of song strings into a single string containing all songs\n",
        "songs_joined = \"\\n\\n\".join(songs) \n",
        "\n",
        "# Find all unique characters in the joined string\n",
        "# N.B. -> \"set\" builds an unordered list of unique characters\n",
        "# N.B. -> \"sorted\" orders them in ascending order\n",
        "vocab = sorted(set(songs_joined))\n",
        "print('There are', len(vocab), \"unique characters in the dataset\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fYIvFDLlH5Hp"
      },
      "source": [
        "# Dataset pre-processing\n",
        "\n",
        "We want to train a RNN to learn patterns in ABC music and generate new music based on such analysis.\n",
        "\n",
        "From a neural network model point of view this means: \n",
        "\n",
        "*Given a character or a sequence of characters, which is the most probable next character?*\n",
        "\n",
        "What we have to do is:\n",
        "\n",
        "* input a sequence of characters to the model\n",
        "* train the model to predict the output, i.e. following characters at each time-step.\n",
        "\n",
        "N.B. RNNs mantain an internal state that depends only on previously seen elements, info about characters seen up until a given moment, will be taken into account when performing prediction."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qS5OGJz7I16T"
      },
      "source": [
        "## Text vectorization\n",
        "\n",
        "We already created the \"alphabet\" of characters contained in the dataset\n",
        "\n",
        "Now we need to define a one-to-one mapping from characters to numbers and viceversa in order for the network to be able to work with the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4zFs9o_jATh_"
      },
      "source": [
        "# Define numerical representation of the text\n",
        "# Create a mapping from character to unique index.\n",
        "# For example, to get the index of the character \"d\", \n",
        "#   we can evaluate `char2idx[\"d\"]`. \n",
        "char2idx = {u:i for i, u in enumerate(vocab)}\n",
        "\n",
        "# Create a mapping from indices to characters. This is\n",
        "#   the inverse of char2idx and allows us to convert back\n",
        "#   from unique index to the character in our vocabulary.\n",
        "idx2char = np.array(vocab)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uyuhtHfzJRab"
      },
      "source": [
        "char2idx"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rd-uvuTcJxN4"
      },
      "source": [
        "### Vectorize the songs string ###. FILL THE CODE\n",
        "\n",
        "'''FILL THE CODE: Write a function to convert the all songs string to a vectorized\n",
        "    (i.e., numeric) representation. Use the appropriate mapping\n",
        "    above to convert from vocab characters to the corresponding indices.\n",
        "\n",
        "  NOTE: the output of the `vectorize_string` function \n",
        "  should be a np.array with `N` elements, where `N` is\n",
        "  the number of characters in the input string\n",
        "\n",
        "'''\n",
        "# def vectorize_string(string):\n",
        "  # FILL THE CODE\n",
        "\n",
        "vectorized_songs = vectorize_string(songs_joined)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pJzrIvZDKFKa"
      },
      "source": [
        "We can also look at how the first part of the text is mapped to an integer representation:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Wnk4p6CJ4G6"
      },
      "source": [
        "print ('{} ---- characters mapped to int ----> {}'.format(repr(songs_joined[:10]), vectorized_songs[:10]))\n",
        "# check that vectorized_songs is a numpy array\n",
        "assert isinstance(vectorized_songs, np.ndarray), \"returned result should be a numpy array\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "83Z5hRepMjq_"
      },
      "source": [
        "## Create training examples and targets\n",
        "\n",
        "We cannot feed the data as it is into the network, we need to divide examples into input and output targets, each of size `seq_length`characters.\n",
        "\n",
        "Since we want to predict the next character, each input will have its output target as a sequence of characters with the same length and shifted to the right of one character.\n",
        "\n",
        "Example, if seq_length is 4 and the sequence is \"Hello\", then we'll have\n",
        "* input_sequence = \"Hell\"\n",
        "* output_sequence = \"ello\"\n",
        "\n",
        "Therefore, we will break our text into chunks of seq_length+1 characters.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JUbhy3SJqGmY"
      },
      "source": [
        "### Batch definition to create training examples ###\n",
        "\n",
        "def get_batch(vectorized_songs, seq_length, batch_size):\n",
        "  # the length of the vectorized songs string\n",
        "  n = vectorized_songs.shape[0] - 1\n",
        "  # randomly choose the starting indices for the examples in the training batch\n",
        "  idx = np.random.choice(n-seq_length, batch_size)\n",
        "\n",
        "  # construct a list of input sequences for the training batch\n",
        "  input_batch = [vectorized_songs[i : i+seq_length] for i in idx]\n",
        "  \n",
        "  #construct a list of output sequences for the training batch\n",
        "  output_batch = [vectorized_songs[i+1 : i+seq_length+1] for i in idx]\n",
        "\n",
        "  # x_batch, y_batch provide the true inputs and targets for network training\n",
        "  x_batch = np.reshape(input_batch, [batch_size, seq_length])\n",
        "  y_batch = np.reshape(output_batch, [batch_size, seq_length])\n",
        "  return x_batch, y_batch\n",
        "\n",
        "\n",
        "# Perform some simple tests to make sure your batch function is working properly! \n",
        "test_args = (vectorized_songs, 10, 2)\n",
        "if not mdl.lab1.test_batch_func_types(get_batch, test_args) or \\\n",
        "   not mdl.lab1.test_batch_func_shapes(get_batch, test_args) or \\\n",
        "   not mdl.lab1.test_batch_func_next_step(get_batch, test_args): \n",
        "   print(\"======\\n[FAIL] could not pass tests\")\n",
        "else: \n",
        "   print(\"======\\n[PASS] passed all tests!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r-zYlAjapFdC"
      },
      "source": [
        "For each of these vectors, each index is processed at a single time step. So, for the input at time step 0, the model receives the index for the first character in the sequence, and tries to predict the index of the next character. At the next timestep, it does the same thing, but the RNN considers the information from the previous step, i.e., its updated state, in addition to the current input.\n",
        "\n",
        "We can make this concrete by taking a look at how this works over the first several characters in our text:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qV8YHLdxpTlK"
      },
      "source": [
        "x_batch, y_batch = get_batch(vectorized_songs, seq_length=5, batch_size=1)\n",
        "for i, (input_idx, target_idx) in enumerate(zip(np.squeeze(x_batch), np.squeeze(y_batch))):\n",
        "    print(\"Step {:3d}\".format(i))\n",
        "    print(\"  input: {} ({:s})\".format(input_idx, repr(idx2char[input_idx])))\n",
        "    print(\"  expected output: {} ({:s})\".format(target_idx, repr(idx2char[target_idx])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Yudvu-Sphex"
      },
      "source": [
        "# RNN Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f0wMiAAuso_X"
      },
      "source": [
        "Now we can define and train a RNN model on the ABC dataset, and then use it to generate new songs.\n",
        "\n",
        "We'll use batches of song snippets as defined in the previous section.\n",
        "\n",
        "We use a LSTM architecture:\n",
        "\n",
        "* state vector mantains information about temporal relationship between consecutive characters.\n",
        "\n",
        "* final output of the LSTM is fed into a fully connected [`Dense`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense) layer, which outputs a [softmax](https://deepai.org/machine-learning-glossary-and-terms/softmax-layer) over each character in the vocabulary.\n",
        "\n",
        "* we sample on the output distribution to predict the next character.\n",
        "\n",
        "To build the model we will use the [`tf.keras.Sequential`](https://www.tensorflow.org/api_docs/python/tf/keras/Sequential) model, as seen in the previous lab.\n",
        "\n",
        "We will use three type of layers:\n",
        "\n",
        "* [`tf.keras.layers.Embedding`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Embedding): This is the input layer, consisting of a trainable lookup table that maps the numbers of each character to a vector with `embedding_dim` dimensions.\n",
        "* [`tf.keras.layers.LSTM`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/LSTM): Our LSTM network, with size `units=rnn_units`. \n",
        "* [`tf.keras.layers.Dense`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense): The output layer, with `vocab_size` outputs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cm166KtTvRQ-"
      },
      "source": [
        "<img src=\"https://raw.githubusercontent.com/aamini/introtodeeplearning/2019/lab1/img/lstm_unrolled-01-01.png\" alt=\"Drawing\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EQ8QWd05wAha"
      },
      "source": [
        "## Define model: FILL THE CODE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TtaLlp7YwDM-"
      },
      "source": [
        "# define the LSTM layer\n",
        "def LSTM(rnn_units):\n",
        "  return tf.keras.layers.LSTM(\n",
        "      rnn_units, # dimensionality of the output space\n",
        "      return_sequences=True, # wheter to return last output or full sequence\n",
        "      recurrent_initializer='glorot_uniform',\n",
        "      recurrent_activation = 'sigmoid',\n",
        "      stateful = True, # last state for each sample at index i in a batch will \n",
        "                       # be used as initial state for the sample of index i in the following batch.\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pHkwrtRmw2jl"
      },
      "source": [
        "# Define RNN model using tf.keras.Sequential: FILL THE CODE\n",
        "\n",
        "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
        "\n",
        "  \"\"\"FILL THE CODE\n",
        "   Build a sequential model consisting of:\n",
        "   - Embedding layer\n",
        "   - LSTM layer\n",
        "   - Fully connected layer\n",
        "  \"\"\"\n",
        "\n",
        "  #model = ...'''TODO'''...\n",
        "    # Layer 1: Embedding layer to transform indices into dense vectors \n",
        "    #   of a fixed embedding size\n",
        "    #...'''TODO'''...\n",
        "\n",
        "    # Layer 2: LSTM with `rnn_units` number of units. \n",
        "    # FILL THE CODE: Call the LSTM function defined above to add this layer.\n",
        "    #...'''TODO'''...\n",
        "\n",
        "    # Layer 3: Dense (fully-connected) layer that transforms the LSTM output\n",
        "    #   into the vocabulary size. \n",
        "    # FILL THE CODE: Add the Dense layer.\n",
        "    #...'''TODO'''...\n",
        "\n",
        "  return model\n",
        "\n",
        "# Build a simple model with default hyperparameters. You will get the \n",
        "#   chance to change these later.\n",
        "model = build_model(len(vocab), embedding_dim=256, rnn_units=1024, batch_size=32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hokofmElyJux"
      },
      "source": [
        "Check summary of the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DXaCUGlRyMIw"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r7U74qdMyPGP"
      },
      "source": [
        "check input/output dimensionality"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SLpuA1VRyRbh"
      },
      "source": [
        "x, y = get_batch(vectorized_songs, seq_length=100, batch_size=32)\n",
        "pred = model(x)\n",
        "print(\"Input shape:      \", x.shape, \" # (batch_size, sequence_length)\")\n",
        "print(\"Prediction shape: \", pred.shape, \"# (batch_size, sequence_length, vocab_size)\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9xtB3ioXzEz7"
      },
      "source": [
        "### Predictions from the untrained model\n",
        "\n",
        "Let's take a look at what our untrained model is predicting.\n",
        "\n",
        "To get actual predictions from the model, we sample from the output distribution, which is defined by a `softmax` over our character vocabulary. This will give us actual character indices. This means we are using a [categorical distribution](https://en.wikipedia.org/wiki/Categorical_distribution) to sample over the example prediction. This gives a prediction of the next character (specifically its index) at each timestep.\n",
        "\n",
        "Note here that we sample from this probability distribution, as opposed to simply taking the `argmax`, which can cause the model to get stuck in a loop.\n",
        "\n",
        "Let's try this sampling out for the first example in the batch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_6PwX3-Dzc6d"
      },
      "source": [
        "sampled_indices = tf.random.categorical(pred[0], num_samples=1)\n",
        "sampled_indices = tf.squeeze(sampled_indices,axis=-1).numpy()\n",
        "sampled_indices"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VBTc7-oLzsoR"
      },
      "source": [
        "We can now decode these to see the text predicted by the untrained model:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eLNAbRZpzoxp"
      },
      "source": [
        "print(\"Input: \\n\", repr(\"\".join(idx2char[x[0]])))\n",
        "print()\n",
        "print(\"Next Char Predictions: \\n\", repr(\"\".join(idx2char[sampled_indices])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FuU1SMArztiG"
      },
      "source": [
        "Prediction is random, as you can see, this is because the network is not trained!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5vT0mgx6z3D6"
      },
      "source": [
        "# Network Training: FILL THE CODE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y0sHYR4a0JRr"
      },
      "source": [
        "Now we can finally start to train the model,\n",
        "\n",
        "the music generation problem is now translated to a character prediction problem, which from a network point of view can be seen as a standard classification problem:\n",
        "\n",
        "Given the previous state of the RNN and the input at a given time step, we want to predict the class of the next character, i.e. predict the next character.\n",
        "\n",
        "We will use the [`sparse_categorical_crossentropy`](https://www.tensorflow.org/api_docs/python/tf/keras/backend/sparse_categorical_crossentropy) loss, which uses integer targets for categorical classification tasks.\n",
        "\n",
        "We'll compute the loss using:\n",
        "\n",
        "* true targets, i.e. *labels*\n",
        "* predicted targets, i.e. *logits*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-SSrIhwu21a6"
      },
      "source": [
        "### Defining the loss function ###\n",
        "\n",
        "'''FILL THE CODE: define the loss function to compute and return the loss between\n",
        "    the true labels and predictions (logits). Set the argument from_logits=True.'''\n",
        "def compute_loss(labels, logits):\n",
        "  # loss =...'''TODO'''...\n",
        "  return loss\n",
        "\n",
        "# compute the loss using the true next characters from the example batch \n",
        "#    and the predictions from the untrained model several cells above\n",
        "# example_batch_loss = ...'''TODO'''...\n",
        "\n",
        "print(\"Prediction shape: \", pred.shape, \" # (batch_size, sequence_length, vocab_size)\") \n",
        "print(\"scalar_loss:      \", example_batch_loss.numpy().mean())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Id39x1Px2_nm"
      },
      "source": [
        "Now we define some hyperparameters in order to train the model, you can then experiment by varying them and see how the train/prediction part changes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qqezz2Y43JiX"
      },
      "source": [
        "### Hyperparameter setting and optimization ###\n",
        "\n",
        "# Optimization parameters:\n",
        "num_training_iterations = 2000  # Increase this to train longer\n",
        "batch_size = 4  # Experiment between 1 and 64\n",
        "seq_length = 100  # Experiment between 50 and 500\n",
        "learning_rate = 5e-3  # Experiment between 1e-5 and 1e-1\n",
        "\n",
        "# Model parameters: \n",
        "vocab_size = len(vocab)\n",
        "embedding_dim = 256 \n",
        "rnn_units = 1024  # Experiment between 1 and 2048\n",
        "\n",
        "# Checkpoint location: \n",
        "checkpoint_dir = './training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"my_ckpt\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uRnf6hKo3Xnb"
      },
      "source": [
        "Now we are ready to define the training operations and actually train the model:\n",
        "\n",
        "* instantiate new model\n",
        "* instantiate optimizer (use [`Adam`](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adam?version=stable), but you can also experiment with other optimizers)\n",
        "* use tf.GradientTape method to perform backpropagation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LjvlVqw93qLO"
      },
      "source": [
        "### Define optimizer and training operation ###\n",
        "\n",
        "'''FILL THE CODE: instantiate a new model for training using the `build_model`\n",
        "  function and the hyperparameters created above.'''\n",
        "# model = build_model('''TODO: arguments''')\n",
        "\n",
        "# Instantiate Adam optimizer\n",
        "# optimizer = ...'''TODO'''...\n",
        "\n",
        "@tf.function\n",
        "def train_step(x, y): \n",
        "  # Use tf.GradientTape()\n",
        "  with tf.GradientTape() as tape:\n",
        "  \n",
        "    '''FILL THE CODE: feed the current input into the model and generate predictions'''\n",
        "    # y_hat =  ...'''TODO'''...\n",
        "  \n",
        "    '''FILL THE CODE: compute the loss!'''\n",
        "    # loss = ...'''TODO'''...\n",
        "\n",
        "  # Now, compute the gradients \n",
        "  '''FILL THE CODE: complete the function call for gradient computation. \n",
        "      Remember that we want the gradient of the loss with respect all \n",
        "      of the model parameters. \n",
        "      HINT: use `model.trainable_variables` to get a list of all model\n",
        "      parameters.'''\n",
        "  # grads = ...'''TODO'''...\n",
        "  \n",
        "  # Apply the gradients to the optimizer so it can update the model accordingly\n",
        "  #optimizer...'''TODO'''...\n",
        "  return loss\n",
        "\n",
        "\n",
        "##################\n",
        "# Begin training!#\n",
        "##################\n",
        "\n",
        "history = []\n",
        "plotter = mdl.util.PeriodicPlotter(sec=2, xlabel='Iterations', ylabel='Loss')\n",
        "if hasattr(tqdm, '_instances'): tqdm._instances.clear() # clear if it exists\n",
        "\n",
        "for iter in tqdm(range(num_training_iterations)):\n",
        "\n",
        "  # Grab a batch and propagate it through the network\n",
        "  x_batch, y_batch = get_batch(vectorized_songs, seq_length, batch_size)\n",
        "  loss = train_step(x_batch, y_batch)\n",
        "\n",
        "  # Update the progress bar\n",
        "  history.append(loss.numpy().mean())\n",
        "  plotter.plot(history)\n",
        "\n",
        "  # Update the model with the changed weights!\n",
        "  if iter % 100 == 0:     \n",
        "    model.save_weights(checkpoint_prefix)\n",
        "    \n",
        "# Save the trained model and the weights\n",
        "model.save_weights(checkpoint_prefix)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A7QTIY7V5G4W"
      },
      "source": [
        "# MUSIC GENERATION\n",
        "\n",
        "Finally we can actually use our trained RNN to generate some music.\n",
        "\n",
        "We need to feed some sort of seed to the model to get it started (otherwise the RNN can't predict anything) and then iteratively predict each successive character.\n",
        "\n",
        "Then, we iterativelly sample from the categorical distributions outputeed from `softmax` over possible successive characters. For inference, we iteratively sample from these distributions and then use our samples to encoder a generated song in ABC format."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SsR6xSVF5-Xw"
      },
      "source": [
        "we'll start by restoring the last saved checkpoint and to keep things simple we use a batch of 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_DQHQM7z53xu"
      },
      "source": [
        "# Restore last saved checkpoint\n",
        "\n",
        "model = build_model(vocab_size, embedding_dim, rnn_units, batch_size=1) # TODO\n",
        "\n",
        "# Restore the model weights for the last checkpoint after training\n",
        "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
        "model.build(tf.TensorShape([1, None]))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RltgMilI6JqD"
      },
      "source": [
        "### Prediction procedure\n",
        "\n",
        "* Initialize a \"seed\" start string and RNN state and set number of characters that we want to generate.\n",
        "\n",
        "* Use start string and RNN state to obtain the probability distribution over the next predicted character.\n",
        "\n",
        "* Sample from multinomial distribution to calculate index of predicted character, which will then be used as next input to the model.\n",
        "\n",
        "* N.B. At each time step, the updated RNN state is fed back into so that the RNN has more context in making the next prediction.\n",
        "\n",
        "After predicting the next character, the updated RNN states are again fed back into the model, which is how it learns sequence dependencies in the data, as it gets more information from the previous predictions.\n",
        "\n",
        "![LSTM inference](https://raw.githubusercontent.com/aamini/introtodeeplearning/2019/lab1/img/lstm_inference.png)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pL8CT_ye7gRn"
      },
      "source": [
        "### Prediction of a generated song ###\n",
        "\n",
        "def generate_text(model, start_string, generation_length=1000):\n",
        "  # Evaluation step (generating ABC text using the learned RNN model)\n",
        "\n",
        "  '''FILL THE CODE: convert the start string to numbers (vectorize)'''\n",
        "  # input_eval = ['''TODO''']\n",
        "\n",
        "  # Add batch dimension\n",
        "  input_eval = tf.expand_dims(input_eval, 0)\n",
        "\n",
        "  # Empty string to store our results\n",
        "  text_generated = []\n",
        "\n",
        "  # Here batch size == 1\n",
        "  model.reset_states()\n",
        "  tqdm._instances.clear()\n",
        "\n",
        "  for i in tqdm(range(generation_length)):\n",
        "      '''FILL THE CODE:: evaluate the inputs and generate the next character predictions'''\n",
        "      # predictions = ... '''TODO'''\n",
        "      \n",
        "      # Remove the batch dimension\n",
        "      predictions = tf.squeeze(predictions, 0)\n",
        "      \n",
        "      '''FILL THE CODE: use a multinomial distribution to sample (hint: tf.random.categorical...)''' \n",
        "      # predicted_id = ...'''TODO''' ....\n",
        "      \n",
        "      # Pass the prediction along with the previous hidden state\n",
        "      #   as the next inputs to the model\n",
        "      input_eval = tf.expand_dims([predicted_id], 0)\n",
        "      \n",
        "      '''FILL THE CODE: add the predicted character to the generated text!'''\n",
        "      # Hint: consider what format the prediction is in vs. the output \n",
        "      # text_generated.append('''TODO''')\n",
        "    \n",
        "  return (start_string + ''.join(text_generated))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "teDfkyPz7oKT"
      },
      "source": [
        "# Use the model and the function defined above to generate ABC format text of length 1000!\n",
        "#    As you may notice, ABC files start with \"X\" - this may be a good start string.'''\n",
        "'''FILL THE CODE: '''\n",
        "# generated_text = generate_text('''TODO''', start_string=\"X\", generation_length=1000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GPRv96bU7pZx"
      },
      "source": [
        "# Play back the music"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dI8M_syn7sLp"
      },
      "source": [
        "### Play back generated songs ###\n",
        "\n",
        "generated_songs = mdl.lab1.extract_song_snippet(generated_text)\n",
        "\n",
        "for i, song in enumerate(generated_songs): \n",
        "  # Synthesize the waveform from a song\n",
        "  waveform = mdl.lab1.play_song(song)\n",
        "\n",
        "  # If its a valid song (correct syntax), lets play it! \n",
        "  if waveform:\n",
        "    print(\"Generated song\", i)\n",
        "    ipythondisplay.display(waveform)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1mIiFRjN3_ZP"
      },
      "source": [
        "# Copyright 2020 MIT 6.S191 Introduction to Deep Learning. All Rights Reserved.\n",
        "# \n",
        "# Licensed under the MIT License. You may not use this file except in compliance\n",
        "# with the License. Use and/or modification of this code outside of 6.S191 must\n",
        "# reference:\n",
        "#\n",
        "# © MIT 6.S191: Introduction to Deep Learning\n",
        "# http://introtodeeplearning.com\n",
        "#"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vV_-CpfL711f"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}